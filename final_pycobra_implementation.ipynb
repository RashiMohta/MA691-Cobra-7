{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import linear_model\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.svm import LinearSVR\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.base import BaseEstimator\n",
    "from sklearn.utils.validation import check_X_y, check_array, check_is_fitted\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "import math\n",
    "import numpy as np\n",
    "import random\n",
    "import logging\n",
    "import numbers\n",
    "\n",
    "\n",
    "logger = logging.getLogger('pycobra.cobra')\n",
    "\n",
    "\n",
    "class Cobra(BaseEstimator):\n",
    "    \"\"\"\n",
    "    COBRA: A combined regression strategy.\n",
    "    Based on the paper by Biau, Fischer, Guedj, Malley [2016].\n",
    "    This is a pythonic implementation of the original COBRA code.\n",
    "    Parameters\n",
    "    ----------\n",
    "    random_state: integer or a numpy.random.RandomState object.\n",
    "        Set the state of the random number generator to pass on to shuffle and loading machines, to ensure\n",
    "        reproducibility of your experiments, for example.\n",
    "    epsilon: float, optional\n",
    "        Epsilon value described in the paper which determines which points are selected for the aggregate.\n",
    "        Default value is determined by optimizing over a grid if test data is provided.\n",
    "        If not, a mean of the possible distances is chosen.\n",
    "    Attributes\n",
    "    ----------\n",
    "    machines_: A dictionary which maps machine names to the machine objects.\n",
    "            The machine object must have a predict method for it to be used during aggregation.\n",
    "    machine_predictions_: A dictionary which maps machine name to it's predictions over X_l\n",
    "            This value is used to determine which points from y_l are used to aggregate.\n",
    "    all_predictions_: numpy array with all the predictions, to be used for epsilon manipulation.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, random_state=None, epsilon=None, machine_list='basic'):\n",
    "        self.random_state = random_state\n",
    "        self.epsilon = epsilon\n",
    "        self.machine_list = machine_list\n",
    "    \n",
    "    def fit(self, X, y, default=True, X_k=None, X_l=None, y_k=None, y_l=None):\n",
    "        \"\"\"\n",
    "        Parameters\n",
    "        ----------\n",
    "        X: array-like, [n_samples, n_features]\n",
    "            Training data which will be used to create the COBRA aggregate.\n",
    "        y: array-like, shape = [n_samples]\n",
    "            Target values used to train the machines used in the aggregation.\n",
    "        default: bool, optional\n",
    "            If set as true then sets up COBRA with default machines and splitting.\n",
    "        X_k : shape = [n_samples, n_features]\n",
    "            Training data which is used to train the machines used in the aggregation.\n",
    "            Can be loaded directly into COBRA; if not, the split_data method is used as default.\n",
    "        y_k : array-like, shape = [n_samples]\n",
    "            Target values used to train the machines used in the aggregation.\n",
    "        X_l : shape = [n_samples, n_features]\n",
    "            Training data which is used to form the aggregate.\n",
    "            Can be loaded directly into COBRA; if not, the split_data method is used as default.\n",
    "        y_l : array-like, shape = [n_samples]\n",
    "            Target values which are actually used to form the aggregate.\n",
    "        \"\"\"\n",
    "\n",
    "        X, y = check_X_y(X, y)\n",
    "        self.X_ = X\n",
    "        self.y_ = y\n",
    "        self.X_k_ = X_k\n",
    "        self.X_l_ = X_l\n",
    "        self.y_k_ = y_k\n",
    "        self.y_l_ = y_l\n",
    "        self.estimators_ = {}\n",
    "        # set-up COBRA with default machines\n",
    "        if default:\n",
    "            self.split_data()\n",
    "            self.load_default(machine_list=self.machine_list)\n",
    "            self.load_machine_predictions()\n",
    "\n",
    "        return self\n",
    "\n",
    "\n",
    "    def set_epsilon(self, X_epsilon=None, y_epsilon=None, grid_points=50):\n",
    "        \"\"\"\n",
    "        Parameters\n",
    "        ----------\n",
    "        X_epsilon : shape = [n_samples, n_features]\n",
    "            Used if no epsilon is passed to find the optimal epsilon for data passed.\n",
    "        y_epsilon : array-like, shape = [n_samples]\n",
    "            Used if no epsilon is passed to find the optimal epsilon for data passed.\n",
    "        grid_points: int, optional\n",
    "            If no epsilon value is passed, this parameter controls how many points on the grid to traverse.\n",
    "   \n",
    "        \"\"\"\n",
    "\n",
    "        # if no epsilon value is passed, we set up COBRA to perform CV and find an optimal epsilon.\n",
    "        if self.epsilon is None and X_epsilon is not None:\n",
    "            self.X_ = X_epsilon\n",
    "            self.y_ = y_epsilon\n",
    "            self.split_data()\n",
    "            self.load_default()\n",
    "            self.load_machine_predictions()\n",
    "            a, size = sorted(self.all_predictions_), len(self.all_predictions_)\n",
    "            res = [a[i + 1] - a[i] for i in range(size) if i+1 < size]\n",
    "            emin = min(res)\n",
    "            emax = max(a) - min(a)\n",
    "            erange = np.linspace(emin, emax, grid_points)\n",
    "            tuned_parameters = [{'epsilon': erange}]\n",
    "            clf = GridSearchCV(self, tuned_parameters, scoring=\"neg_mean_squared_error\")\n",
    "            clf.fit(X_epsilon, y_epsilon)\n",
    "            self.epsilon = clf.best_params_[\"epsilon\"]\n",
    "            self.estimators_, self.machine_predictions_ = {}, {}\n",
    "\n",
    "    \n",
    "    def pred_surv(self, X, alpha, info=False):\n",
    "        \"\"\"\n",
    "        Performs the COBRA aggregation scheme, used in predict method.\n",
    "        Parameters\n",
    "        ----------\n",
    "        X: array-like, [n_features]\n",
    "        alpha: int, optional\n",
    "            alpha refers to the number of machines the prediction must be close to to be considered during aggregation.\n",
    "        info: boolean, optional\n",
    "            If info is true the list of points selected in the aggregation is returned.\n",
    "        Returns\n",
    "        -------\n",
    "        avg_surv: Average survival function prediction\n",
    "        \"\"\"\n",
    "\n",
    "        # dictionary mapping machine to points selected\n",
    "        select = {}\n",
    "        for machine in self.estimators_:\n",
    "            # machine prediction\n",
    "            val = self.estimators_[machine].predict(X)\n",
    "            select[machine] = set()\n",
    "            # iterating from l to n\n",
    "            # replace with numpy iteration\n",
    "            for count in range(0, len(self.X_l_)):\n",
    "                try:\n",
    "                    # if value is close to prediction, select the indice\n",
    "                    if math.fabs(self.machine_predictions_[machine][count] - val) <= self.epsilon:\n",
    "                        select[machine].add(count)\n",
    "                except (ValueError, TypeError) as e:\n",
    "                    logger.info(\"Error in indice selection\")\n",
    "                    continue\n",
    "\n",
    "        points = []\n",
    "        # count is the indice number.\n",
    "        for count in range(0, len(self.X_l_)):\n",
    "            # row check is number of machines which picked up a particular point\n",
    "            row_check = 0\n",
    "            for machine in select:\n",
    "                if count in select[machine]:\n",
    "                    row_check += 1\n",
    "            if row_check == alpha:\n",
    "                points.append(count)\n",
    "\n",
    "        # if no points are selected, return 0\n",
    "        if len(points) == 0:\n",
    "            if info:\n",
    "                logger.info(\"No points were selected, prediction is 0\")\n",
    "                return (0, 0)\n",
    "            return None\n",
    "\n",
    "        # aggregate\n",
    "        avg_surv = None\n",
    "        # points = [pt for pt in points if self.y_l_[pt][0]]\n",
    "        \n",
    "        for point in points:\n",
    "            for machine in select:\n",
    "                val = self.estimators_[machine].predict_surv(self.X_l_[point].reshape(1,-1))[0]\n",
    "                if avg_surv is None:\n",
    "                    avg_surv = val\n",
    "                else:\n",
    "                    avg_surv += val\n",
    "        avg_surv = avg_surv / avg_surv[0]\n",
    "\n",
    "        if info:\n",
    "            return avg_surv, points\n",
    "        return avg_surv\n",
    "    \n",
    "    \n",
    "    def predict_survival_function(self, X, alpha=None, info=False):\n",
    "        \"\"\"\n",
    "        Performs the COBRA aggregation scheme, calls pred_surv.\n",
    "        Parameters\n",
    "        ----------\n",
    "        X: array-like, [n_features]\n",
    "        alpha: int, optional\n",
    "            alpha refers to the number of machines the prediction must be close to to be considered during aggregation.\n",
    "        info: boolean, optional\n",
    "            If info is true the list of points selected in the aggregation is returned.\n",
    "        Returns\n",
    "        -------\n",
    "        result: predicted survival function\n",
    "        \"\"\"\n",
    "\n",
    "        # sets alpha as the total number of machines as a default value\n",
    "\n",
    "        X = check_array(X)\n",
    "\n",
    "        if alpha is None:\n",
    "            alpha = len(self.estimators_)\n",
    "        if X.ndim == 1:\n",
    "            return self.pred_surv(X.reshape(1, -1), info=info, alpha=alpha)\n",
    "\n",
    "        result = [None]*len(X)\n",
    "        avg_points = 0\n",
    "        index = 0\n",
    "        for vector in X:\n",
    "            if info:\n",
    "                result[index], points = self.pred_surv(vector.reshape(1, -1), info=info, alpha=alpha)\n",
    "                avg_points += len(points)\n",
    "            else:\n",
    "                result[index] = self.pred_surv(vector.reshape(1, -1), info=info, alpha=alpha)\n",
    "            index += 1\n",
    "\n",
    "        result = np.array(result)\n",
    "        \n",
    "        if info:\n",
    "            avg_points = avg_points / len(X_array)\n",
    "            return result, avg_points\n",
    "\n",
    "        return result\n",
    "\n",
    "    def split_data(self, k=None, l=None, shuffle_data=False):\n",
    "        \"\"\"\n",
    "        Split the data into different parts for training machines and for aggregation.\n",
    "        Parameters\n",
    "        ----------\n",
    "        k : int, optional\n",
    "            k is the number of points used to train the machines.\n",
    "            Those are the first k points of the data provided.\n",
    "        l: int, optional\n",
    "            l is the number of points used to form the COBRA aggregate.\n",
    "        shuffle: bool, optional\n",
    "            Boolean value to decide to shuffle the data before splitting.\n",
    "        Returns\n",
    "        -------\n",
    "        self : returns an instance of self.\n",
    "        \"\"\"\n",
    "\n",
    "        if shuffle_data:\n",
    "            self.X_, self.y_ = shuffle(self.X_, self.y_, random_state=self.random_state)\n",
    "\n",
    "        if k is None and l is None:\n",
    "            k = int(len(self.X_) / 2)\n",
    "            l = int(len(self.X_))\n",
    "\n",
    "        if k is not None and l is None:\n",
    "            l = len(self.X_) - k\n",
    "\n",
    "        if l is not None and k is None:\n",
    "            k = len(self.X_) - l\n",
    "\n",
    "        self.X_k_ = self.X_[:k]\n",
    "        self.X_l_ = self.X_[k:l]\n",
    "        self.y_k_ = self.y_[:k]\n",
    "        self.y_l_ = self.y_[k:l]\n",
    "\n",
    "        return self\n",
    "\n",
    "\n",
    "    def load_machine(self, machine_name, machine):\n",
    "        \"\"\"\n",
    "        Adds a machine to be used during the aggregation strategy.\n",
    "        The machine object must have been trained using X_k and y_k, and must have a 'predict()' method.\n",
    "        After the machine is loaded, for it to be used during aggregation, load_machine_predictions must be run.\n",
    "        Parameters\n",
    "        ----------\n",
    "        machine_name : string\n",
    "            Name of the machine you are loading\n",
    "        machine: machine/regressor object\n",
    "            The regressor machine object which is mapped to the machine_name\n",
    "        Returns\n",
    "        -------\n",
    "        self : returns an instance of self.\n",
    "        \"\"\"\n",
    "\n",
    "        self.estimators_[machine_name] = machine\n",
    "\n",
    "        return self\n",
    "\n",
    "\n",
    "    def load_machine_predictions(self, predictions=None):\n",
    "        \"\"\"\n",
    "        Stores the trained machines' predicitons on training data in a dictionary, to be used for predictions.\n",
    "        Should be run after all the machines to be used for aggregation is loaded.\n",
    "        Parameters\n",
    "        ----------\n",
    "        predictions: dictionary, optional\n",
    "            A pre-existing machine:predictions dictionary can also be loaded.\n",
    "        Returns\n",
    "        -------\n",
    "        self : returns an instance of self.\n",
    "        \"\"\"\n",
    "        self.machine_predictions_ = {}\n",
    "        self.all_predictions_ = np.array([])\n",
    "        if predictions is None:\n",
    "            for machine in self.estimators_:\n",
    "                self.machine_predictions_[machine] = self.estimators_[machine].predict(self.X_l_)\n",
    "                # all_predictions_ is used in the diagnostics class, and for initialising epsilon\n",
    "                self.all_predictions_ = np.append(self.all_predictions_, self.machine_predictions_[machine])\n",
    "\n",
    "        if predictions is not None:\n",
    "            self.machine_predictions_ = predictions\n",
    "\n",
    "        return self"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sksurv.tree import SurvivalTree\n",
    "\n",
    "class CobraSurvivalTree(SurvivalTree):\n",
    "\n",
    "    def __init__(self, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        \n",
    "    def predict_surv(self, X, return_array=True):\n",
    "        return super().predict_survival_function(X,return_array=return_array)\n",
    "    \n",
    "    def fit(self, *args, **kwargs):\n",
    "        return super().fit(*args, **kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nfrom sksurv.ensemble import RandomSurvivalForest\\n\\nclass CobraSurvivalForest(RandomSurvivalForest):\\n    \\n    def __init__(self, **kwargs):\\n        super().__init__(**kwargs)\\n        \\n    def predict_surv(self, X, return_array=True):\\n        return super().predict_survival_function(X,return_array=return_array)\\n    \\n    def fit(self, *args, **kwargs):\\n        return super().fit(*args, **kwargs)'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "from sksurv.ensemble import RandomSurvivalForest\n",
    "\n",
    "class CobraSurvivalForest(RandomSurvivalForest):\n",
    "    \n",
    "    def __init__(self, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        \n",
    "    def predict_surv(self, X, return_array=True):\n",
    "        return super().predict_survival_function(X,return_array=return_array)\n",
    "    \n",
    "    def fit(self, *args, **kwargs):\n",
    "        return super().fit(*args, **kwargs)\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "%matplotlib inline\n",
    "\n",
    "from lifelines.utils import concordance_index\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sksurv.tree import SurvivalTree\n",
    "from sksurv.datasets import load_gbsg2\n",
    "from sksurv.preprocessing import OneHotEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = load_gbsg2()\n",
    "X.loc[:, \"tgrade\"] = X.loc[:, \"tgrade\"].map(len).astype(int)\n",
    "Xt = OneHotEncoder().fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style  type=\"text/css\" >\n",
       "#T_ce95ed65_4957_11ec_93e6_d037454475c0row6_col1,#T_ce95ed65_4957_11ec_93e6_d037454475c0row7_col1,#T_ce95ed65_4957_11ec_93e6_d037454475c0row9_col1{\n",
       "            background-color:  lightgreen;\n",
       "        }</style><table id=\"T_ce95ed65_4957_11ec_93e6_d037454475c0\" ><thead>    <tr>        <th class=\"col_heading level0 col0\" >time</th>        <th class=\"col_heading level0 col1\" >event</th>    </tr></thead><tbody>\n",
       "                <tr>\n",
       "                                <td id=\"T_ce95ed65_4957_11ec_93e6_d037454475c0row0_col0\" class=\"data row0 col0\" >1814.000000</td>\n",
       "                        <td id=\"T_ce95ed65_4957_11ec_93e6_d037454475c0row0_col1\" class=\"data row0 col1\" >True</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                                <td id=\"T_ce95ed65_4957_11ec_93e6_d037454475c0row1_col0\" class=\"data row1 col0\" >2018.000000</td>\n",
       "                        <td id=\"T_ce95ed65_4957_11ec_93e6_d037454475c0row1_col1\" class=\"data row1 col1\" >True</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                                <td id=\"T_ce95ed65_4957_11ec_93e6_d037454475c0row2_col0\" class=\"data row2 col0\" >712.000000</td>\n",
       "                        <td id=\"T_ce95ed65_4957_11ec_93e6_d037454475c0row2_col1\" class=\"data row2 col1\" >True</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                                <td id=\"T_ce95ed65_4957_11ec_93e6_d037454475c0row3_col0\" class=\"data row3 col0\" >1807.000000</td>\n",
       "                        <td id=\"T_ce95ed65_4957_11ec_93e6_d037454475c0row3_col1\" class=\"data row3 col1\" >True</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                                <td id=\"T_ce95ed65_4957_11ec_93e6_d037454475c0row4_col0\" class=\"data row4 col0\" >772.000000</td>\n",
       "                        <td id=\"T_ce95ed65_4957_11ec_93e6_d037454475c0row4_col1\" class=\"data row4 col1\" >True</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                                <td id=\"T_ce95ed65_4957_11ec_93e6_d037454475c0row5_col0\" class=\"data row5 col0\" >448.000000</td>\n",
       "                        <td id=\"T_ce95ed65_4957_11ec_93e6_d037454475c0row5_col1\" class=\"data row5 col1\" >True</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                                <td id=\"T_ce95ed65_4957_11ec_93e6_d037454475c0row6_col0\" class=\"data row6 col0\" >2172.000000</td>\n",
       "                        <td id=\"T_ce95ed65_4957_11ec_93e6_d037454475c0row6_col1\" class=\"data row6 col1\" >False</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                                <td id=\"T_ce95ed65_4957_11ec_93e6_d037454475c0row7_col0\" class=\"data row7 col0\" >2161.000000</td>\n",
       "                        <td id=\"T_ce95ed65_4957_11ec_93e6_d037454475c0row7_col1\" class=\"data row7 col1\" >False</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                                <td id=\"T_ce95ed65_4957_11ec_93e6_d037454475c0row8_col0\" class=\"data row8 col0\" >471.000000</td>\n",
       "                        <td id=\"T_ce95ed65_4957_11ec_93e6_d037454475c0row8_col1\" class=\"data row8 col1\" >True</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                                <td id=\"T_ce95ed65_4957_11ec_93e6_d037454475c0row9_col0\" class=\"data row9 col0\" >2014.000000</td>\n",
       "                        <td id=\"T_ce95ed65_4957_11ec_93e6_d037454475c0row9_col1\" class=\"data row9 col1\" >False</td>\n",
       "            </tr>\n",
       "    </tbody></table>"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x1220885b220>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_y = pd.DataFrame(data={'time': [y[i][1] for i in range(len(y))], 'event': [y[i][0] for i in range(len(y))]})\n",
    "df_y[:10].style.hide_index().highlight_min('event', color='lightgreen')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_state = 20\n",
    "X_train, X_test, y_train, y_test = train_test_split(Xt, y, test_size=0.25, random_state=random_state)\n",
    "times = np.arange(365, 1826)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Cobra(epsilon=1000)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "survCobra = Cobra(epsilon=1000)\n",
    "survCobra.fit(X_train,y_train,default=False)\n",
    "for i in range(4):\n",
    "    survTree = CobraSurvivalTree(splitter='random', random_state=i)\n",
    "    survTree.fit(X_train,y_train)\n",
    "    survCobra.load_machine(f'survTree_{i:2d}',survTree)\n",
    "\"\"\"for i in range(2):\n",
    "    survForest = CobraSurvivalForest(n_estimators=1000,min_samples_split=10,min_samples_leaf=15,max_features=\"sqrt\",n_jobs=-1,\n",
    "                           random_state=i)\n",
    "    survForest.fit(X_train,y_train)\n",
    "    survCobra.load_machine(f'survForest_{i:2d}',survForest)\"\"\"\n",
    "eventTimes = survTree.event_times_\n",
    "survCobra.split_data()\n",
    "survCobra.load_machine_predictions()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = survCobra.predict_survival_function(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.        , 0.99715429, 0.99388578, ..., 0.46394191, 0.46174664,\n",
       "        0.45498197],\n",
       "       [1.        , 0.99715429, 0.99388578, ..., 0.46394191, 0.46174664,\n",
       "        0.45498197],\n",
       "       [1.        , 0.99715429, 0.99388578, ..., 0.46394191, 0.46174664,\n",
       "        0.45498197],\n",
       "       ...,\n",
       "       [1.        , 0.99715429, 0.99388578, ..., 0.46394191, 0.46174664,\n",
       "        0.45498197],\n",
       "       [1.        , 0.99715429, 0.99388578, ..., 0.46394191, 0.46174664,\n",
       "        0.45498197],\n",
       "       [1.        , 0.99715429, 0.99388578, ..., 0.46394191, 0.46174664,\n",
       "        0.45498197]])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.2032254887884249\n"
     ]
    }
   ],
   "source": [
    "from scipy.interpolate import interp1d\n",
    "from sksurv.metrics import integrated_brier_score\n",
    "times = np.arange(365, 1826)\n",
    "preds = []\n",
    "\n",
    "for i in range(len(y)):\n",
    "    step_fun = interp1d(eventTimes, y[i], kind='previous')\n",
    "    preds.append(np.asarray([step_fun(t) for t in times]))\n",
    "\n",
    "score = integrated_brier_score(y_test, y_test, preds, times)\n",
    "print(score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
